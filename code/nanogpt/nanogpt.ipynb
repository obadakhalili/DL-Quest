{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn, TinyJit, Device\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device.DEFAULT = \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"shakespeare.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394 chars\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus), \"chars\")\n",
    "print(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(corpus)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, \"\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_line_char = \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = lambda s: [vocab.index(c) for c in s]\n",
    "decode = lambda l: \"\".join([vocab[i] for i in l])\n",
    "\n",
    "decode(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tensor(encode(corpus))\n",
    "split = int(0.9 * len(data))\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data: Tensor, batch_size, block_size):\n",
    "  indices = Tensor.randint((batch_size,), high=len(data) - block_size).reshape(\n",
    "    (batch_size, 1)\n",
    "  ) + Tensor.arange(block_size)\n",
    "  return data[indices], data[indices + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 8), (4, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(train_data, batch_size=4, block_size=8)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ather ha', 'e in arm', 'if mysel', 't seeing']\n",
      "['ther had', ' in arms', 'f myself', ' seeing,']\n"
     ]
    }
   ],
   "source": [
    "print([decode(row) for row in x.numpy()])\n",
    "print([decode(row) for row in y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "  def __init__(self, embed_size: int, head_size: int) -> None:\n",
    "    self.head_size = head_size\n",
    "    self.query = nn.Linear(embed_size, self.head_size, bias=False)\n",
    "    self.key = nn.Linear(embed_size, self.head_size, bias=False)\n",
    "    self.value = nn.Linear(embed_size, self.head_size, bias=False)\n",
    "\n",
    "  def __call__(self, x: Tensor) -> Tensor:\n",
    "    B, T, C = x.shape\n",
    "\n",
    "    Q = self.query(x)\n",
    "    K = self.key(x)\n",
    "    dot_attn = Q @ K.transpose(-2, -1)\n",
    "    scaled_dot_attn: Tensor = dot_attn / (self.head_size**0.5)\n",
    "    mask = Tensor.ones((T, T), requires_grad=False).tril()\n",
    "    masked_scaled_dot_attn = scaled_dot_attn.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    attn_scores = masked_scaled_dot_attn.softmax()\n",
    "\n",
    "    V = self.value(x)\n",
    "    attented_embeds = attn_scores @ V\n",
    "    return attented_embeds\n",
    "\n",
    "class Transformer:\n",
    "  def __init__(self, block_size: int, vocab_size: int, embed_size: int) -> None:\n",
    "    self.block_size = block_size\n",
    "    self.vocab_size = vocab_size\n",
    "    self.token_embed = nn.Embedding(vocab_size, embed_size)\n",
    "    self.attn = Attention(embed_size, embed_size)\n",
    "    self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "  def __call__(self, x: Tensor) -> Tensor:\n",
    "    logits = x.sequential([self.token_embed, self.attn, self.lm_head])\n",
    "    return logits\n",
    "\n",
    "  def loss(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "    logits = self(x)\n",
    "    loss = logits.sparse_categorical_crossentropy(y)\n",
    "    return logits, loss\n",
    "\n",
    "  def generate(self, x: Tensor, n: int = 500) -> Tensor:\n",
    "    assert len(x.shape) == 1 and x.shape[0] == self.block_size\n",
    "    x = x.unsqueeze(0)\n",
    "    for _ in range(n):\n",
    "      logits = self(x[:, -self.block_size:])\n",
    "      p = logits[:, -1, :].softmax().squeeze(0)\n",
    "      next_token = np.random.choice(self.vocab_size, p=p.numpy())\n",
    "      x = x.cat(Tensor([[next_token]]), dim=1)\n",
    "    return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853057"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 256\n",
    "embed_size = 512\n",
    "n_heads = 4\n",
    "head_size = embed_size // n_heads\n",
    "transformer = Transformer(block_size=block_size, vocab_size=vocab_size, embed_size=embed_size)\n",
    "sum(p.numel() for p in nn.state.get_parameters(transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.optim.AdamW(nn.state.get_parameters(transformer))\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "@TinyJit\n",
    "@Tensor.train()\n",
    "def train_step():\n",
    "  optim.zero_grad()\n",
    "  x_samples, y_samples = get_batch(train_data, batch_size, block_size)\n",
    "  _, loss = transformer.loss(x_samples, y_samples)\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, loss 4.17, acc 9.31%\n",
      "step 500, loss 2.51, acc 26.10%\n",
      "step 1000, loss 2.47, acc 26.66%\n",
      "step 1500, loss 2.47, acc 26.96%\n",
      "step 2000, loss 2.48, acc 27.00%\n",
      "step 2500, loss 2.45, acc 26.72%\n",
      "step 3000, loss 2.43, acc 26.90%\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for step in range(1, 3001):\n",
    "  loss = train_step().item()\n",
    "  losses.append(loss)\n",
    "  if step == 1 or step % 500 == 0:\n",
    "    with Tensor.inference_mode():\n",
    "      x_samples, y_samples = get_batch(test_data, batch_size, block_size)\n",
    "      acc = (transformer(x_samples).argmax(axis=-1) == y_samples).mean().item()\n",
    "      print(f\"step {step}, loss {loss:.2f}, acc {acc*100.:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mFirst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "\u001b[0m\n",
      "Clende no hat all ad ide y d gie,\n",
      "Dot un's br; iar.\n",
      "RDoussiro ice.\n",
      "MEed Er GOUSdein my Lat is beeioderr,\n",
      "WANoas ke, VO: he nup; y, n Qt IUENI'smoundengat yofilo.\n",
      "Or aipof trkeshis t yorey wasseeal towir'sanslsorsomas hmalie, t t ou ck ceref gid Vis t be ancedang ak to sallemotondeis gothe's, O:\n",
      "AN y su than,\n",
      "S:\n",
      "GS:\n",
      "ABELUDRUCht pre t t\n",
      "Iour t welur mmy?\n",
      "Weng mf RGRtith o this hounshil ft.\n",
      "A,\n",
      "e I wh whor st ary othore s. sin leranan the flen bequlath;\n",
      "A mano myove thend prdistorusinththou hes g p\n"
     ]
    }
   ],
   "source": [
    "text = decode(transformer.generate(data[:block_size]).numpy())\n",
    "print(\"\\033[92m\" + text[:block_size] + \"\\033[0m\" + text[block_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
