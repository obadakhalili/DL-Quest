{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn, TinyJit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"shakespeare.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394 chars\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus), \"chars\")\n",
    "print(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(corpus)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, \"\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_line_char = \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = lambda s: [vocab.index(c) for c in s]\n",
    "decode = lambda l: \"\".join([vocab[i] for i in l])\n",
    "\n",
    "decode(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tensor(encode(corpus))\n",
    "split = int(0.9 * len(data))\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data: Tensor, batch_size, block_size):\n",
    "  indices = Tensor.randint((batch_size,), high=len(data) - block_size).reshape(\n",
    "    (batch_size, 1)\n",
    "  ) + Tensor.arange(block_size)\n",
    "  return data[indices], data[indices + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 8), (4, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(train_data, batch_size=4, block_size=8)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ther boo', 'thy nobl', \"'ll swea\", 'ht in ju']\n",
      "['her book', 'hy noble', 'll swear', 't in jus']\n"
     ]
    }
   ],
   "source": [
    "print([decode(row) for row in x.numpy()])\n",
    "print([decode(row) for row in y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram:\n",
    "  def __init__(self, vocab_size: int):\n",
    "    assert vocab_size >= 1\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embed = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "  def __call__(self, x: Tensor) -> Tensor:\n",
    "    assert len(x.shape) == 1\n",
    "    return self.embed(x.reshape((-1, 1))).squeeze(1)\n",
    "\n",
    "  def loss(self, logits: Tensor, y: Tensor) -> Tensor:\n",
    "    assert (\n",
    "      len(logits.shape) == 2\n",
    "      and len(y.shape) == 1\n",
    "      and logits.shape[0] == y.shape[0]\n",
    "      and logits.shape[1] == self.vocab_size\n",
    "    )\n",
    "    return logits.sparse_categorical_crossentropy(y)\n",
    "\n",
    "  def generate(self, x: Tensor, max_len=50):\n",
    "    with Tensor.inference_mode():\n",
    "      for _ in range(max_len):\n",
    "        prev_x = x[-1:]\n",
    "        p = self(prev_x).squeeze().softmax().numpy()\n",
    "        next_x = Tensor([np.random.choice(vocab_size, p=p)])\n",
    "        x = x.cat(next_x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Bigram(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.optim.AdamW(nn.state.get_parameters(bigram))\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "@TinyJit\n",
    "@Tensor.train()\n",
    "def train_step():\n",
    "  optim.zero_grad()\n",
    "  x_samples, y_samples = get_batch(train_data, batch_size, block_size=1)\n",
    "  loss = bigram.loss(bigram(x_samples.reshape(-1)), y_samples.reshape(-1)).backward()\n",
    "  optim.step()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, loss 4.19, acc 1.53%\n",
      "step 1000, loss 3.40, acc 24.57%\n",
      "step 2000, loss 3.03, acc 26.38%\n",
      "step 3000, loss 2.70, acc 26.54%\n",
      "step 4000, loss 2.72, acc 27.20%\n",
      "step 5000, loss 2.52, acc 27.05%\n",
      "step 6000, loss 2.62, acc 27.08%\n",
      "step 7000, loss 2.54, acc 27.06%\n",
      "step 8000, loss 2.62, acc 27.06%\n",
      "step 9000, loss 2.41, acc 27.01%\n",
      "step 10000, loss 2.32, acc 27.01%\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for step in range(1, 10001):\n",
    "  loss = train_step().item()\n",
    "  losses.append(loss)\n",
    "  if step == 1 or step % 1000 == 0:\n",
    "    with Tensor.inference_mode():\n",
    "      acc = (bigram(test_data[:-1]).argmax(axis=1) == test_data[1:]).mean().item()\n",
    "      print(f\"step {step}, loss {loss:.2f}, acc {acc*100.:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thy d hatlises acearJUn weanegD aXHenossbA wareh ias:\n",
      "IZigre thy ber ugm askem m'simucjceres agery, antsaco avor.\n",
      "MELYo;\n",
      "Fr thaveELI waplat ke buthefost pd acoghes heithind,\n",
      "\n",
      "che f Ye canco groues! aien stirsou ts tevenend themeresoru? Gupgsor:\n",
      "AUKE hat, tS:\n",
      "OLand be INCound, s ke dond to'd.\n",
      "RIULayend nor seFath cos upp'stheae onve caker?\n",
      "se t wous t.\n",
      "HI t iooravathect wo,\n",
      "Inggicul y BRDYod\n",
      "I:\n",
      "\n",
      "qul pitonarreicMan'suaumy nt th, thangar oome rta we I's t teathe cinr desha\n",
      "Moake, a r. hos;\n",
      "I iongha\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  decode(bigram.generate(Tensor([vocab.index(new_line_char)]), max_len=500).numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 1000, 100, 200\n",
    "x = Tensor.randint((B, T, C))\n",
    "\n",
    "\n",
    "def using_cumsum():\n",
    "  a = x.cumsum(axis=1)\n",
    "  b = a / Tensor.arange(1, T + 1).reshape((T, 1))\n",
    "\n",
    "\n",
    "def using_matmul():\n",
    "  a = Tensor.ones((T, T)).tril() @ x\n",
    "  b = a / Tensor.arange(1, T + 1).reshape((T, 1))\n",
    "\n",
    "\n",
    "def using_softmax():\n",
    "  a = Tensor.ones((T, T)).tril().where(0, float(\"-inf\")).softmax()\n",
    "  b = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.38381759660478565),\n",
       " np.float64(0.4886868394010889),\n",
       " np.float64(0.44910617659606944))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "(\n",
    "  np.mean(timeit.repeat(using_cumsum, repeat=10000, number=1)) * 1000,\n",
    "  np.mean(timeit.repeat(using_matmul, repeat=10000, number=1)) * 1000,\n",
    "  np.mean(timeit.repeat(using_softmax, repeat=10000, number=1)) * 1000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
