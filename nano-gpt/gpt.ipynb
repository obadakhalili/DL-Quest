{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Tensor, nn, TinyJit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"shakespeare.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394 chars\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus), \"chars\")\n",
    "print(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(corpus)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, \"\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_line_char = \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = lambda s: [vocab.index(c) for c in s]\n",
    "decode = lambda l: \"\".join([vocab[i] for i in l])\n",
    "\n",
    "decode(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Tensor(encode(corpus))\n",
    "split = int(0.9 * len(data))\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data: Tensor, batch_size, block_size):\n",
    "  indices = Tensor.randint((batch_size,), high=len(data) - block_size).reshape(\n",
    "    (batch_size, 1)\n",
    "  ) + Tensor.arange(block_size)\n",
    "  return data[indices], data[indices + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 8), (4, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(train_data, batch_size=4, block_size=8)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nAnd fro', 'brazen w', 'my soldi', 'ng his f']\n",
      "['And from', 'razen wa', 'y soldie', 'g his fo']\n"
     ]
    }
   ],
   "source": [
    "print([decode(row) for row in x.numpy()])\n",
    "print([decode(row) for row in y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram:\n",
    "  def __init__(self, vocab_size: int):\n",
    "    assert vocab_size >= 1\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embed = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "  def __call__(self, x: Tensor) -> Tensor:\n",
    "    assert len(x.shape) == 1\n",
    "    return self.embed(x.reshape((-1, 1))).squeeze(1)\n",
    "\n",
    "  def loss(self, logits: Tensor, y: Tensor) -> Tensor:\n",
    "    assert (\n",
    "      len(logits.shape) == 2\n",
    "      and len(y.shape) == 1\n",
    "      and logits.shape[0] == y.shape[0]\n",
    "      and logits.shape[1] == self.vocab_size\n",
    "    )\n",
    "    return logits.sparse_categorical_crossentropy(y)\n",
    "\n",
    "  def generate(self, x: Tensor, max_len=50):\n",
    "    with Tensor.inference_mode():\n",
    "      for _ in range(max_len):\n",
    "        prev_x = x[-1:]\n",
    "        p = self(prev_x).squeeze().softmax().numpy()\n",
    "        next_x = Tensor([np.random.choice(vocab_size, p=p)])\n",
    "        x = x.cat(next_x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Bigram(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.optim.AdamW(nn.state.get_parameters(bigram))\n",
    "batch_size = 128\n",
    "\n",
    "@TinyJit\n",
    "@Tensor.train()\n",
    "def train_step():\n",
    "  optim.zero_grad()\n",
    "  x_samples, y_samples = get_batch(train_data, batch_size, block_size=1)\n",
    "  loss = bigram.loss(bigram(x_samples.reshape(-1)), y_samples.reshape(-1)).backward()\n",
    "  optim.step()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, loss 4.19, acc 1.83%\n",
      "step 1000, loss 3.41, acc 22.44%\n",
      "step 2000, loss 2.93, acc 26.31%\n",
      "step 3000, loss 2.73, acc 26.89%\n",
      "step 4000, loss 2.69, acc 26.93%\n",
      "step 5000, loss 2.69, acc 26.91%\n",
      "step 6000, loss 2.63, acc 26.91%\n",
      "step 7000, loss 2.51, acc 26.95%\n",
      "step 8000, loss 2.52, acc 26.97%\n",
      "step 9000, loss 2.66, acc 26.91%\n",
      "step 10000, loss 2.63, acc 27.01%\n",
      "step 11000, loss 2.27, acc 26.98%\n",
      "step 12000, loss 2.46, acc 26.74%\n",
      "step 13000, loss 2.36, acc 27.01%\n",
      "step 14000, loss 2.36, acc 26.99%\n",
      "step 15000, loss 2.41, acc 26.98%\n",
      "step 16000, loss 2.60, acc 26.97%\n",
      "step 17000, loss 2.49, acc 26.97%\n",
      "step 18000, loss 2.44, acc 27.01%\n",
      "step 19000, loss 2.39, acc 27.01%\n",
      "step 20000, loss 2.41, acc 27.01%\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for step in range(1, 20001):\n",
    "  loss = train_step().item()\n",
    "  losses.append(loss)\n",
    "  if step == 1 or step % 1000 == 0:\n",
    "    with Tensor.inference_mode():\n",
    "      acc = (bigram(test_data[:-1]).argmax(axis=1) == test_data[1:]).mean().item()\n",
    "      print(f\"step {step}, loss {loss:.2f}, acc {acc*100.:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O:\n",
      "Matr deneas, Doule angh ho busor VINGUSiserr ck o y te the! Balty d y Gr itre br el mecineset Momen merdgo kere VCOfan'for, s?\n",
      "DY ad I I fo mans\n",
      "DUMBEWhin.\n",
      "Whathetrofe hid ate\n",
      "I:\n",
      "LELAnto, s torce,\n",
      "MINUhillvorthend,\n",
      "Serofofe Bilictlas o an!\n",
      "HAnosepofowir.felint A lonye moupunonour ntom l; gsow hemelion torthy s f me aperve k fe ashoJULe f\n",
      "\n",
      "Dus tie leis t bllerd thanouprey, o ing atid saimangore t tatate, manecha it muis, h hel\n",
      "Thende lk'd stheeaie, at areret\n",
      "Thepes:\n",
      "Ser reas I.\n",
      "\n",
      "ENTou lin' l f\n"
     ]
    }
   ],
   "source": [
    "print(decode(bigram.generate(Tensor([vocab.index(new_line_char)]), max_len=500).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 1000, 100, 200\n",
    "x = Tensor.randint((B, T, C))\n",
    "\n",
    "def using_cumsum():\n",
    "  a = x.cumsum(axis=1)\n",
    "  b = a / Tensor.arange(1, T+1).reshape((T, 1))\n",
    "\n",
    "\n",
    "def using_matmul():\n",
    "  a = Tensor.ones((T, T)).tril() @ x\n",
    "  b = a / Tensor.arange(1, T+1).reshape((T, 1))\n",
    "\n",
    "\n",
    "def using_softmax():\n",
    "  a = Tensor.ones((T, T)).tril().where(0, float(\"-inf\")).softmax()\n",
    "  b = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7295794918107276),\n",
       " np.float64(0.935482974491606),\n",
       " np.float64(1.0409363099006441))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "np.mean(timeit.repeat(using_cumsum, repeat=10000, number=1)) * 1000, np.mean(timeit.repeat(using_matmul, repeat=10000, number=1)) * 1000, np.mean(timeit.repeat(using_softmax, repeat=10000, number=1)) * 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
